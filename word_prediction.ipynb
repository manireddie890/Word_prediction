{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tjYfI0uXbsYD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3Os806jnIgHB"
      },
      "outputs": [],
      "source": [
        "with open('/content/Sheet_1.csv', 'r', encoding='utf-8') as file:\n",
        "    data = file.read().lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XDAd_sVuCXVg"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "sequences = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v6VG5seQCbFk"
      },
      "outputs": [],
      "source": [
        "tokens = tokenizer.texts_to_sequences([data])[0]\n",
        "for i in range(1, len(tokens)):\n",
        "    seq = tokens[:i+1]\n",
        "    sequences.append(seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oV-QvKrPChlv"
      },
      "outputs": [],
      "source": [
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IExIVWJlC5wA"
      },
      "outputs": [],
      "source": [
        "# Features and Labels\n",
        "X, y = sequences[:, :-1], sequences[:, -1]\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2oe1EmWDCsU",
        "outputId": "6760881a-676c-4563-d6ef-bcd2548a7151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Build the Model\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 50, input_length=max_sequence_len-1),\n",
        "    LSTM(150, return_sequences=False),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "KZ78ppf8DCu7",
        "outputId": "f71e8550-7416-469a-cfda-e87f414ba6af"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xix6DgxVDJJV",
        "outputId": "01746f38-0968-474a-dba1-99e7fb29b8cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "88/88 - 391s - 4s/step - accuracy: 0.0327 - loss: 6.0842\n",
            "Epoch 2/20\n",
            "88/88 - 444s - 5s/step - accuracy: 0.0355 - loss: 5.6747\n",
            "Epoch 3/20\n",
            "88/88 - 440s - 5s/step - accuracy: 0.0501 - loss: 5.5250\n",
            "Epoch 4/20\n",
            "88/88 - 445s - 5s/step - accuracy: 0.0664 - loss: 5.3746\n",
            "Epoch 5/20\n",
            "88/88 - 391s - 4s/step - accuracy: 0.0817 - loss: 5.2443\n",
            "Epoch 6/20\n",
            "88/88 - 443s - 5s/step - accuracy: 0.0927 - loss: 5.1400\n",
            "Epoch 7/20\n",
            "88/88 - 446s - 5s/step - accuracy: 0.1016 - loss: 5.0266\n",
            "Epoch 8/20\n",
            "88/88 - 434s - 5s/step - accuracy: 0.1083 - loss: 4.9189\n",
            "Epoch 9/20\n",
            "88/88 - 390s - 4s/step - accuracy: 0.1097 - loss: 4.8017\n",
            "Epoch 10/20\n",
            "88/88 - 390s - 4s/step - accuracy: 0.1243 - loss: 4.6867\n",
            "Epoch 11/20\n",
            "88/88 - 385s - 4s/step - accuracy: 0.1367 - loss: 4.5641\n",
            "Epoch 12/20\n",
            "88/88 - 447s - 5s/step - accuracy: 0.1442 - loss: 4.4341\n",
            "Epoch 13/20\n",
            "88/88 - 438s - 5s/step - accuracy: 0.1587 - loss: 4.3119\n",
            "Epoch 14/20\n",
            "88/88 - 445s - 5s/step - accuracy: 0.1729 - loss: 4.1826\n",
            "Epoch 15/20\n",
            "88/88 - 384s - 4s/step - accuracy: 0.1825 - loss: 4.0568\n",
            "Epoch 16/20\n",
            "88/88 - 386s - 4s/step - accuracy: 0.1960 - loss: 3.9329\n",
            "Epoch 17/20\n",
            "88/88 - 387s - 4s/step - accuracy: 0.2106 - loss: 3.8055\n",
            "Epoch 18/20\n",
            "88/88 - 440s - 5s/step - accuracy: 0.2322 - loss: 3.6797\n",
            "Epoch 19/20\n",
            "88/88 - 444s - 5s/step - accuracy: 0.2504 - loss: 3.5564\n",
            "Epoch 20/20\n",
            "88/88 - 442s - 5s/step - accuracy: 0.2720 - loss: 3.4291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b06f5202b60>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Train the Model\n",
        "model.fit(X, y, epochs=20, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "q5qpG6Jxlc5n"
      },
      "outputs": [],
      "source": [
        "# Predict Function\n",
        "def predict_next_word(seed_text, num_words=1):\n",
        "    for _ in range(num_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model.predict(token_list, verbose=0)\n",
        "        next_word = tokenizer.index_word[np.argmax(predicted)]\n",
        "        seed_text += \" \" + next_word\n",
        "    return seed_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sW8Tr8ILljV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a9b744f-e8b6-48f3-f599-b3261cf13a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text: I am friendly with a same friend\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"I am friendly with\"\n",
        "next_words = predict_next_word(seed_text, num_words=3)\n",
        "print(\"Generated Text:\", next_words)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}